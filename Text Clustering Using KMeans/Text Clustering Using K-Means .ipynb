{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read the train data and save it in dataframe after splitting by new lines\n",
    "with open('train.dat','r') as f:\n",
    "    df = pd.DataFrame(l.split(\"\\t\") for l in f) \n",
    "df.columns = [\"term-freq\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def getLebelsAndFreq(r):       \n",
    "        c = len(r)\n",
    "        lebel=[]\n",
    "        frequency =[]\n",
    "        for i in range(c):\n",
    "            if(i%2 ==0):\n",
    "                lebel.append(r[i])\n",
    "                if(i<c):\n",
    "                    frequency.append(r[i+1])\n",
    "        return lebel,frequency  \n",
    "\n",
    "def get_mode(l):\n",
    "    sum1 = sum( i*i for i in l)\n",
    "    return (sum1**0.5)\n",
    "\n",
    "def get_dotProduct(l1,f1,l2,f2,common_lebel):\n",
    "    dot_product = 0\n",
    "    for i in common_lebel:\n",
    "        loc1 = l1.index(i)\n",
    "        floc1 = f1[loc1]\n",
    "    \n",
    "        loc2 = l2.index(i)\n",
    "        floc2 = f2[loc2]\n",
    "        dot_product = dot_product + (floc1 * floc2)\n",
    "    return dot_product\n",
    "    \n",
    "def getCosineSimilarity(d1,d2):\n",
    "    freq1 = d1.split()  \n",
    "    r1 = [float(i) for i in freq1]    \n",
    "        \n",
    "    freq2 = d2.split()  \n",
    "    r2 = [float(i) for i in freq2]\n",
    "\n",
    "    \n",
    "    l2,f2 = getLebelsAndFreq(r2)\n",
    "    l1,f1 = getLebelsAndFreq(r1)\n",
    "\n",
    "    common_lebel =set(l2) & set(l1)\n",
    "    common_lebel = list(common_lebel)\n",
    "    \n",
    "    dot_product = get_dotProduct(l1,f1,l2,f2,common_lebel)\n",
    "    mode = get_mode(l1) * get_mode(l2)\n",
    "    cos_sim = (dot_product/mode)\n",
    "    return cos_sim\n",
    "\n",
    "def getEuclideanDistance(d1,d2):\n",
    "    freq1 = d1.split()  \n",
    "    r1 = [float(i) for i in freq1]    \n",
    "        \n",
    "    freq2 = d2.split()  \n",
    "    r2 = [float(i) for i in freq2]\n",
    "\n",
    "    \n",
    "    l2,f2 = getLebelsAndFreq(r2)\n",
    "    l1,f1 = getLebelsAndFreq(r1)\n",
    "\n",
    "    common_lebel =set(l2) & set(l1)\n",
    "    common_lebel = list(common_lebel)\n",
    "    \n",
    "    summation = 0\n",
    "    for i in common_lebel:\n",
    "        loc1 = l1.index(i)\n",
    "        floc1 = f1[loc1]\n",
    "    \n",
    "        loc2 = l2.index(i)\n",
    "        floc2 = f2[loc2]\n",
    "        summation =  (floc1-floc2)**2\n",
    "    sqrt_sum = (summation ** 0.5)    \n",
    "    return sqrt_sum\n",
    "    \n",
    "    \n",
    "\n",
    "def getAverage(clf,doc_count):\n",
    "    feature_dict={}\n",
    "    if(clf):\n",
    "        d = clf[0].split(' ')\n",
    "        l = len(d)\n",
    "        for i in range(l):\n",
    "            old_value = 0.0\n",
    "            v = 0.0\n",
    "            if(i%2==0 and i<l):\n",
    "                k = d[i]\n",
    "                v = d[i+1]\n",
    "                if(k in feature_dict):\n",
    "                    old_value = feature_dict.get(k)\n",
    "                    feature_dict[k] = float(old_value) + float(v)                     \n",
    "                else:\n",
    "                    feature_dict[k] = float(v)\n",
    "    avg_list=[]\n",
    "    for k,v in feature_dict.items():\n",
    "        avg_list.append(k)\n",
    "        avg_freq = float((v/doc_count))\n",
    "        avg_list.append(avg_freq)\n",
    "           \n",
    "    if(len(avg_list)>0):\n",
    "        strg =''\n",
    "        for i in avg_list:\n",
    "            strg = strg +' '+str(i)\n",
    "        strg = strg.strip()    \n",
    "        TESTDATA=StringIO(strg)\n",
    "        df1 = pd.read_csv(TESTDATA)\n",
    "        return df1.columns.values\n",
    "        \n",
    "def getDifference(cc,pc):\n",
    "    if (cc is None or pc is None):\n",
    "        return 0\n",
    "    elif(len(cc)==0 or len(pc)==0):\n",
    "        return 0\n",
    "    else:\n",
    "        listpc = pc.split(' ')\n",
    "        c = len(listpc)\n",
    "        c= c-1\n",
    "        lebel_pc=[]\n",
    "        for i in range(c):\n",
    "            if(i%2 ==0):\n",
    "                lebel_pc.append(listpc[i])\n",
    "                \n",
    "        listcc = cc[0].split(' ')\n",
    "        d = len(listcc)\n",
    "        d= d-1\n",
    "        lebel_cc=[]\n",
    "        for i in range(d):\n",
    "            if(i%2 ==0 and i<d):\n",
    "                lebel_cc.append(listcc[i+1])\n",
    "        common_lebel = set(lebel_pc).intersection(lebel_cc)\n",
    "        return (len(common_lebel))\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCosineSimilaritySecondTime(d1,d2):\n",
    "    freq1 = d1.split()  \n",
    "    r1 = [float(i) for i in freq1]    \n",
    "    l1 = len(d2)\n",
    "    if(l1==1):\n",
    "        all_one = d2[0]\n",
    "        l_one = all_one.split(' ')\n",
    "        r2 = [float(i) for i in l_one]   \n",
    "    else:\n",
    "        freq2 = d2.split(' ')  \n",
    "        r2 = [float(i) for i in freq2]\n",
    "    l2,f2 = getLebelsAndFreq(r2)\n",
    "    l1,f1 = getLebelsAndFreq(r1)\n",
    "\n",
    "    common_lebel =set(l2) & set(l1)\n",
    "    common_lebel = list(common_lebel)\n",
    "    \n",
    "    dot_product = get_dotProduct(l1,f1,l2,f2,common_lebel)\n",
    "    mode = get_mode(l1) * get_mode(l2)\n",
    "    cos_sim = (dot_product/mode)\n",
    "    return cos_sim\n",
    "\n",
    "def getEuclideanDistanceSecondTime(d1,d2):\n",
    "    freq1 = d1.split()  \n",
    "    r1 = [float(i) for i in freq1]    \n",
    "    l1 = len(d2)\n",
    "    if(l1==1):\n",
    "        all_one = d2[0]\n",
    "        l_one = all_one.split(' ')\n",
    "        r2 = [float(i) for i in l_one]   \n",
    "    else:\n",
    "        freq2 = d2.split(' ')  \n",
    "        r2 = [float(i) for i in freq2]\n",
    "    l2,f2 = getLebelsAndFreq(r2)\n",
    "    l1,f1 = getLebelsAndFreq(r1)\n",
    "\n",
    "    common_lebel =set(l2) & set(l1)\n",
    "    common_lebel = list(common_lebel)\n",
    "    \n",
    "    summation = 0\n",
    "    for i in common_lebel:\n",
    "        loc1 = l1.index(i)\n",
    "        floc1 = f1[loc1]\n",
    "    \n",
    "        loc2 = l2.index(i)\n",
    "        floc2 = f2[loc2]\n",
    "        summation =  (floc1-floc2)**2\n",
    "    sqrt_sum = (summation ** 0.5)    \n",
    "    return sqrt_sum\n",
    "\n",
    "def getDifferenceSecondTime(cc,pc):\n",
    "    if (cc is None or pc is None):\n",
    "        return 0\n",
    "    elif(len(cc)==0 or len(pc)==0):\n",
    "        return 0\n",
    "    else:\n",
    "        listpc = pc[0].split(' ')\n",
    "        c = len(listpc)\n",
    "        c= c-1\n",
    "        lebel_pc=[]\n",
    "        for i in range(c):\n",
    "            if(i%2 ==0 and i<c):\n",
    "                lebel_pc.append(listpc[i])\n",
    "                \n",
    "        listcc = cc[0].split(' ')\n",
    "        d = len(listcc)\n",
    "        d= d-1\n",
    "        lebel_cc=[]\n",
    "        for i in range(d):\n",
    "            if(i%2 ==0 and i<d):\n",
    "                lebel_cc.append(listcc[i])\n",
    "        \n",
    "        common_lebel = set(lebel_pc).intersection(lebel_cc)\n",
    "        return (len(common_lebel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Kmeans using centroid distance \n",
    "class K_Means:\n",
    "    def _init_(self, k =7, tol =500, max_itr = 30):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_itr = max_itr\n",
    "        \n",
    "    def fit(self,data,k,iteration):\n",
    "        output = open(\"output.dat\", 'w') \n",
    "        self.centroids = {}\n",
    "        \n",
    "        for i in range(k):\n",
    "            d = data[\"term-freq\"][i]\n",
    "            self.centroids[i] = d\n",
    "            optimized_set = set()\n",
    "        for i in range(iteration):\n",
    "            print(\"Iteration number is \"+str(i))\n",
    "            #print('Already Optimized Centroids')\n",
    "            #print(optimized_set)\n",
    "            self.classifications = {}\n",
    "            cluster_count ={}\n",
    "            output = open(\"output.dat\", 'w') \n",
    "            for j in range(k):\n",
    "                self.classifications[j] = [] \n",
    "                distances = []\n",
    "            for featureset in data[\"term-freq\"]:\n",
    "                if(i==0):\n",
    "                    distances = [getCosineSimilarity(featureset,centroid) for centroid in list(self.centroids.values())]\n",
    "                else:\n",
    "                    distances = [getCosineSimilaritySecondTime(featureset,centroid) for centroid in list(self.centroids.values())]\n",
    "                classification = distances.index(min(distances)) \n",
    "                clt = classification + 1\n",
    "                output.write(str(clt)+'\\n')\n",
    "                self.classifications[classification].append(featureset)\n",
    "                if(classification in cluster_count):\n",
    "                    old_value = cluster_count.get(classification)\n",
    "                    cluster_count[classification] = float(old_value) + 1.00                     \n",
    "                else:\n",
    "                    cluster_count[classification] = 1\n",
    "                \n",
    "            prev_centroids = dict(self.centroids)\n",
    "\n",
    "            for clf in self.classifications:\n",
    "                clff = getAverage(self.classifications[clf],cluster_count.get(clf))\n",
    "                if(clff is None):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.centroids[clf] = clff\n",
    "            optimized = True    \n",
    "            output.close()\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                previous_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if(i==0 ):\n",
    "                    if getDifference(current_centroid,previous_centroid)< 30:\n",
    "                        #print('Not Optimized')\n",
    "                        if(i==2):\n",
    "                            open('output.dat', 'w').close()\n",
    "                        optimized = False\n",
    "                    else:\n",
    "                        optimized_set.add(c)\n",
    "                else:\n",
    "                    if getDifferenceSecondTime(current_centroid,previous_centroid)< 30:\n",
    "                        #print('Not Optimized')\n",
    "                        if(i==2):\n",
    "                            open('output.dat', 'w').close()\n",
    "                        optimized = False\n",
    "                    else:\n",
    "                        optimized_set.add(c)\n",
    "    \n",
    "            if optimized:\n",
    "                break; \n",
    "        output.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number is 0\n"
     ]
    }
   ],
   "source": [
    "clf = K_Means()\n",
    "clf.fit(df,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
